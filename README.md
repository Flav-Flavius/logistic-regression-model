# Logistic Regression Model for DMV Test Data

## ğŸ“Œ Project Overview

This project implements a **Logistic Regression Model** to predict whether a candidate will pass or fail the **DMV Written Test** based on their scores from two written exams. The model is trained using **gradient descent** and evaluated through cost function analysis and decision boundary visualization.

## ğŸ“‚ Files in This Repository

- `logistic_regression.ipynb` - Jupyter Notebook containing the complete implementation.
- `DMV_Written_Tests.csv` - Dataset containing the candidates' test scores.
- `cost_function_over_iterations.png` - Graph showing cost function convergence.
- `README.md` - Project documentation (this file).

## ğŸš€ Features Implemented

- Data visualization using **Seaborn & Matplotlib** ğŸ“Š
- Implementation of the **Sigmoid function** âš¡
- Cost function computation (Log Loss) ğŸ“‰
- Gradient Descent for model optimization ğŸ”„
- Decision boundary visualization âœ¨
- Model accuracy evaluation ğŸ“ˆ
- Predicting outcomes for new candidates ğŸ¯

## ğŸ”¬ Key Functions Explained

- **`logistic_function(x)`** â†’ Implements the sigmoid activation function.
- **`compute_cost(theta, x, y)`** â†’ Computes the cost function (Log Loss) and its gradient.
- **`gradient_descent(x, y, theta, alpha, iterations)`** â†’ Optimizes the model parameters using gradient descent.
- **`predict(theta, x)`** â†’ Predicts outcomes based on trained weights.

## ğŸ“· Visualizations

- **Scatter plot** of test scores with pass/fail markers.
- **Cost function convergence** over iterations.
- **Decision boundary** separating passing and failing candidates.

## ğŸ’¡ Future Improvements

- Implement **regularization** to prevent overfitting.
- Test with **larger datasets** for improved generalization.
- Explore alternative **optimization algorithms**.

---

**ğŸ”— Author: [Cenuse Flavius]**  
ğŸš€ Connect with me on [LinkedIn](https://www.linkedin.com/in/flavius-cenuse/)  
ğŸ Follow me on [GitHub](https://github.com/Flav-Flavius)
